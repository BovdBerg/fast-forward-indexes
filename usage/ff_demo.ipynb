{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-terrier fast-forward-indexes # torch==1.13.1 (version too old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8841823/8841823 [00:15<00:00, 581160.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from fast_forward import OnDiskIndex, Mode, Ranking\n",
    "from fast_forward.encoder import TCTColBERTQueryEncoder\n",
    "\n",
    "encoder = TCTColBERTQueryEncoder(\"castorini/tct_colbert-msmarco\")\n",
    "ff_index = OnDiskIndex.load(\n",
    "    Path(\"../ff_msmarco-v1-passage.tct_colbert.h5\"), encoder, Mode.MAXP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Please confirm you agree to the MSMARCO data usage agreement found at <http://www.msmarco.org/dataset.aspx>\n",
      "[INFO] [starting] https://trec.nist.gov/data/deep/2019qrels-pass.txt\n",
      "[INFO] [finished] https://trec.nist.gov/data/deep/2019qrels-pass.txt: [00:00] [187kB] [460kB/s]\n",
      "[INFO] [starting] https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test2019-queries.tsv.gz\n",
      "[INFO] [finished] https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test2019-queries.tsv.gz: [00:00] [4.28kB] [24.5MB/s]\n",
      "/home/bovdberg/miniconda3/envs/thesis/lib/python3.10/site-packages/fast_forward/ranking.py:298: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "import ir_datasets\n",
    "\n",
    "dataset = ir_datasets.load(\"msmarco-passage/trec-dl-2019/judged\")\n",
    "r = Ranking.from_file(\n",
    "    Path(\"msmarco-passage-test2019-sparse10000.txt\"),\n",
    "    {q.query_id: q.text for q in dataset.queries_iter()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fast_forward.index:computed scores in 144.32676931499964 seconds\n"
     ]
    }
   ],
   "source": [
    "# standard re-ranking, probably takes a few min\n",
    "ff_out = ff_index(r.cut(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fast_forward.index:depth 800: 16 queries left\n",
      "INFO:fast_forward.index:depth 5000: 9 queries left\n",
      "INFO:fast_forward.index:computed scores in 157.70563292299994 seconds\n"
     ]
    }
   ],
   "source": [
    "# re-ranking with early stopping\n",
    "ff_out_es = ff_index(\n",
    "    r.cut(5000),\n",
    "    early_stopping=10,\n",
    "    early_stopping_alpha=0.2,\n",
    "    early_stopping_intervals=(800, 5000),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no re-ranking:\n",
      " {AP(rel=2)@1000: 0.30128706043561426, RR(rel=2)@10: 0.7024178663713547} \n",
      "\n",
      "standard re-ranking:\n",
      " {AP(rel=2)@1000: 0.45949573660757204, RR(rel=2)@10: 0.901937984496124} \n",
      "\n",
      "re-ranking with early stopping:\n",
      " {RR(rel=2)@10: 0.901937984496124}\n"
     ]
    }
   ],
   "source": [
    "from ir_measures import calc_aggregate, AP, RR\n",
    "from fast_forward.util import to_ir_measures\n",
    "\n",
    "print(\n",
    "    \"no re-ranking:\\n\",\n",
    "    calc_aggregate(\n",
    "        [AP(rel=2) @ 1000, RR(rel=2) @ 10], dataset.qrels_iter(), to_ir_measures(r)\n",
    "    ),\n",
    "    \"\\n\\nstandard re-ranking:\\n\",\n",
    "    calc_aggregate(\n",
    "        [AP(rel=2) @ 1000, RR(rel=2) @ 10],\n",
    "        dataset.qrels_iter(),\n",
    "        to_ir_measures(r.interpolate(ff_out, 0.2)),\n",
    "    ),\n",
    "    \"\\n\\nre-ranking with early stopping:\\n\",\n",
    "    calc_aggregate(\n",
    "        [RR(rel=2) @ 10],\n",
    "        dataset.qrels_iter(),\n",
    "        to_ir_measures(r.interpolate(ff_out_es, 0.2)),\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ranking')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e757c603b03bb5364a2e7c54e488a14c8c5b6d905c56042b6aec9e13d3e2c7b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
