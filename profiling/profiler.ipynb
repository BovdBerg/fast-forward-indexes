{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The profiles can be viewed by running in the Linux command line:\n",
    "```\n",
    "tuna path/to/rerank_ff.prof --port=8000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "device_type = \"cpu\" # \"cpu\" or \"gpu\"\n",
    "k_s = 1000\n",
    "in_memory = False\n",
    "path_to_dir = \"../../ff-data/\"\n",
    "h5_filename = \"ff_msmarco-v1-passage.tct_colbert.h5\"\n",
    "ranking_filename = \"msmarco-passage-test2019-sparse10000.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_to_h5_file = Path(path_to_dir + h5_filename)\n",
    "path_to_ranking_file = Path(path_to_dir + ranking_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.1 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import pyterrier as pt\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init(tqdm=\"notebook\")\n",
    "\n",
    "# Create profile directory\n",
    "mem = \"mem\" if in_memory else \"disk\"\n",
    "profile_dir = f\"profiles/{h5_filename}/{device_type}_k{k_s}_{mem}/\"\n",
    "if not os.path.exists(profile_dir):\n",
    "    os.makedirs(profile_dir)\n",
    "\n",
    "device_name = \"cuda\" if device_type == \"gpu\" else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bvdb9/miniconda3/envs/ff/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 8841823/8841823 [00:37<00:00, 233191.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from fast_forward import OnDiskIndex, Mode, Ranking\n",
    "from fast_forward.encoder import TCTColBERTQueryEncoder\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "with cProfile.Profile() as profile:\n",
    "    q_encoder = TCTColBERTQueryEncoder(\n",
    "        \"castorini/tct_colbert-msmarco\", \n",
    "        device=device_name\n",
    "    )\n",
    "    ff_index = OnDiskIndex.load(\n",
    "        path_to_h5_file,\n",
    "        query_encoder=q_encoder, \n",
    "        mode=Mode.MAXP\n",
    "    )\n",
    "\n",
    "    if in_memory:\n",
    "        ff_index = ff_index.to_memory()\n",
    "\n",
    "stats = pstats.Stats(profile)\n",
    "stats.sort_stats(pstats.SortKey.TIME)\n",
    "stats.dump_stats(profile_dir + \"index.prof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bvdb9/miniconda3/envs/ff/lib/python3.12/site-packages/fast_forward/ranking.py:298: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "import ir_datasets\n",
    "dataset = ir_datasets.load(\"msmarco-passage/trec-dl-2019/judged\")\n",
    "r = Ranking.from_file(\n",
    "    path_to_ranking_file,\n",
    "    {q.query_id: q.text for q in dataset.queries_iter()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fast_forward.index:computed scores in 108.27997793000031 seconds\n"
     ]
    }
   ],
   "source": [
    "# standard re-ranking, probably takes a few min\n",
    "with cProfile.Profile() as profile:\n",
    "    ff_out = ff_index(r.cut(k_s))\n",
    "\n",
    "stats = pstats.Stats(profile)\n",
    "stats.sort_stats(pstats.SortKey.TIME)\n",
    "stats.dump_stats(profile_dir + \"rerank_ff.prof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fast_forward.index:depth 800: 16 queries left\n",
      "INFO:fast_forward.index:depth 5000: 16 queries left\n",
      "INFO:fast_forward.index:computed scores in 186.87780905199998 seconds\n"
     ]
    }
   ],
   "source": [
    "# re-ranking with early stopping, also takes a few min\n",
    "with cProfile.Profile() as profile:\n",
    "    ff_out_es = ff_index(\n",
    "        r.cut(k_s),\n",
    "        early_stopping=10,\n",
    "        early_stopping_alpha=0.2,\n",
    "        early_stopping_intervals=(800, 5000),\n",
    "    )\n",
    "\n",
    "stats = pstats.Stats(profile)\n",
    "stats.sort_stats(pstats.SortKey.TIME)\n",
    "stats.dump_stats(profile_dir + \"rerank_ff_es.prof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical retrieval without re-ranking:\n",
      " {AP(rel=2)@1000: 0.30128706043561426, RR(rel=2)@10: 0.7024178663713547} \n",
      "\n",
      "... with fast-forward re-ranking:\n",
      " {AP(rel=2)@1000: 0.43803324500109636, RR(rel=2)@10: 0.8941860465116279} \n",
      "\n",
      "... with fast-forward re-ranking AND early stopping:\n",
      " {RR(rel=2)@10: 0.8941860465116279}\n"
     ]
    }
   ],
   "source": [
    "from ir_measures import calc_aggregate, AP, RR\n",
    "from fast_forward.util import to_ir_measures\n",
    "\n",
    "print(\n",
    "    \"Lexical retrieval without re-ranking:\\n\",\n",
    "    calc_aggregate(\n",
    "        [AP(rel=2) @ 1000, RR(rel=2) @ 10], dataset.qrels_iter(), to_ir_measures(r)\n",
    "    ),\n",
    "    \"\\n\\n... with fast-forward re-ranking:\\n\",\n",
    "    calc_aggregate(\n",
    "        [AP(rel=2) @ 1000, RR(rel=2) @ 10],\n",
    "        dataset.qrels_iter(),\n",
    "        to_ir_measures(r.interpolate(ff_out, 0.2)),\n",
    "    ),\n",
    "    \"\\n\\n... with fast-forward re-ranking AND early stopping:\\n\",\n",
    "    calc_aggregate(\n",
    "        [RR(rel=2) @ 10],\n",
    "        dataset.qrels_iter(),\n",
    "        to_ir_measures(r.interpolate(ff_out_es, 0.2)),\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ranking')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e757c603b03bb5364a2e7c54e488a14c8c5b6d905c56042b6aec9e13d3e2c7b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
