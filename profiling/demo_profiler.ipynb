{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The profiles can be viewed by running in the Linux command line:\n",
    "```\n",
    "tuna path/to/rerank_ff.prof --port=8000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import ir_datasets\n",
    "import torch\n",
    "\n",
    "### PARAMETERS SETTINGS\n",
    "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "k_s = 1000\n",
    "in_memory = False\n",
    "index_path = Path(\"/home/bvdb9/indices/msm-psg/ff/ff_index_TCTColBERT_opq.h5\")\n",
    "sparse_ranking_path = Path(\"/home/bvdb9/sparse_rankings/msmarco-passage-test2019-sparse10000.txt\")\n",
    "dataset = ir_datasets.load(\"msmarco-passage/trec-dl-2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.1 has loaded Terrier 5.10 (built by craigm on 2024-08-22 17:33) and terrier-helper 0.0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import pyterrier as pt\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init(tqdm=\"notebook\")\n",
    "\n",
    "# Create profile directory\n",
    "mem = \"mem\" if in_memory else \"disk\"\n",
    "profile_dir = f\"profiles/{index_path}/{device_name}_k{k_s}_{mem}/\"\n",
    "if not os.path.exists(profile_dir):\n",
    "    os.makedirs(profile_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bvdb9/miniconda3/envs/ff/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Successfully loaded faiss with AVX2 support.\n",
      "Loading index: 100%|██████████| 8841823/8841823 [00:21<00:00, 420848.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from fast_forward import OnDiskIndex, Mode, Ranking\n",
    "from fast_forward.encoder import TCTColBERTQueryEncoder\n",
    "import pstats\n",
    "\n",
    "q_encoder = TCTColBERTQueryEncoder(\n",
    "    \"castorini/tct_colbert-msmarco\", \n",
    "    device=device_name\n",
    ")\n",
    "ff_index = OnDiskIndex.load(\n",
    "    index_path,\n",
    "    query_encoder=q_encoder, \n",
    "    mode=Mode.MAXP\n",
    ")\n",
    "\n",
    "if in_memory:\n",
    "    ff_index = ff_index.to_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_ranking = Ranking.from_file(\n",
    "    sparse_ranking_path,\n",
    "    {q.query_id: q.text for q in dataset.queries_iter()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fast_forward.index:_compute_scores: create df with unique queries and ids 0 ... n\n",
      "INFO:fast_forward.index:_compute_scores: _get_vectors\n",
      "Getting vectors: 100%|██████████| 42791/42791 [00:00<00:00, 237683.93it/s]\n",
      "Processing vectors: 100%|██████████| 42791/42791 [00:00<00:00, 261003.77it/s]\n",
      "Reading vectors: 100%|██████████| 42/42 [00:12<00:00,  3.24it/s]\n",
      "INFO:fast_forward.index:_compute_scores: self.quantizer=<class 'fast_forward.quantizer.nanopq.NanoOPQ'>\n",
      "INFO:fast_forward.index:_compute_scores: decode vectors\n",
      "Decoding subspaces: 100%|██████████| 96/96 [00:00<00:00, 240.95it/s]\n",
      "INFO:fast_forward.index:_compute_scores: decode vectors done\n",
      "Computing scores: 100%|██████████| 43000/43000 [00:00<00:00, 116894.39it/s]\n",
      "INFO:fast_forward.index:_compute_scores: compute all dot products (scores)\n",
      "INFO:fast_forward.index:_compute_scores: calculate each query-doc pair's ff_score\n",
      "INFO:fast_forward.index:computed scores in 19.003987617999883 seconds\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "# standard re-ranking, probably takes a few min\n",
    "with cProfile.Profile() as profile:\n",
    "    dense_ranking = ff_index(sparse_ranking.cut(k_s))\n",
    "\n",
    "stats = pstats.Stats(profile)\n",
    "stats.sort_stats(pstats.SortKey.TIME)\n",
    "stats.dump_stats(profile_dir + \"rerank_ff.prof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fast_forward.index:depth 800: 43 queries left\n",
      "INFO:fast_forward.index:_compute_scores: create df with unique queries and ids 0 ... n\n",
      "INFO:fast_forward.index:_compute_scores: _get_vectors\n",
      "Getting vectors: 100%|██████████| 34273/34273 [00:00<00:00, 190132.49it/s]\n",
      "Processing vectors: 100%|██████████| 34273/34273 [00:00<00:00, 256379.79it/s]\n",
      "Reading vectors: 100%|██████████| 34/34 [00:06<00:00,  5.48it/s]\n",
      "INFO:fast_forward.index:_compute_scores: self.quantizer=<class 'fast_forward.quantizer.nanopq.NanoOPQ'>\n",
      "INFO:fast_forward.index:_compute_scores: decode vectors\n",
      "Decoding subspaces: 100%|██████████| 96/96 [00:00<00:00, 217.95it/s]\n",
      "INFO:fast_forward.index:_compute_scores: decode vectors done\n",
      "Computing scores: 100%|██████████| 34400/34400 [00:00<00:00, 93624.25it/s]\n",
      "INFO:fast_forward.index:_compute_scores: compute all dot products (scores)\n",
      "INFO:fast_forward.index:_compute_scores: calculate each query-doc pair's ff_score\n",
      "INFO:fast_forward.index:depth 5000: 14 queries left\n",
      "INFO:fast_forward.index:_compute_scores: create df with unique queries and ids 0 ... n\n",
      "INFO:fast_forward.index:_compute_scores: _get_vectors\n",
      "Getting vectors: 100%|██████████| 2799/2799 [00:00<00:00, 126483.91it/s]\n",
      "Processing vectors: 100%|██████████| 2799/2799 [00:00<00:00, 252774.46it/s]\n",
      "Reading vectors: 100%|██████████| 3/3 [00:01<00:00,  2.66it/s]\n",
      "INFO:fast_forward.index:_compute_scores: self.quantizer=<class 'fast_forward.quantizer.nanopq.NanoOPQ'>\n",
      "INFO:fast_forward.index:_compute_scores: decode vectors\n",
      "Decoding subspaces: 100%|██████████| 96/96 [00:00<00:00, 3823.39it/s]\n",
      "INFO:fast_forward.index:_compute_scores: decode vectors done\n",
      "Computing scores: 100%|██████████| 2800/2800 [00:00<00:00, 47833.77it/s]\n",
      "INFO:fast_forward.index:_compute_scores: compute all dot products (scores)\n",
      "INFO:fast_forward.index:_compute_scores: calculate each query-doc pair's ff_score\n",
      "INFO:fast_forward.index:computed scores in 10.8793635359998 seconds\n"
     ]
    }
   ],
   "source": [
    "# re-ranking with early stopping, also takes a few min\n",
    "with cProfile.Profile() as profile:\n",
    "    dense_ranking_es = ff_index(\n",
    "        sparse_ranking.cut(k_s),\n",
    "        early_stopping=10,\n",
    "        early_stopping_alpha=0.2,\n",
    "        early_stopping_depths=(800, 5000),\n",
    "    )\n",
    "\n",
    "stats = pstats.Stats(profile)\n",
    "stats.sort_stats(pstats.SortKey.TIME)\n",
    "stats.dump_stats(profile_dir + \"rerank_ff_es.prof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse ranking:\n",
      " {RR(rel=2)@10: 0.7024178663713547, AP(rel=2)@1000: 0.30128706043561426, nDCG@10: 0.5058310024399073} \n",
      "\n",
      "Dense ranking:\n",
      " {RR(rel=2)@10: 0.8294573643410852, AP(rel=2)@1000: 0.4126229893533601, nDCG@10: 0.6795683451708543} \n",
      "\n",
      "... with fast-forward re-ranking (alpha=0.2):\n",
      " {RR(rel=2)@10: 0.8748615725359912, AP(rel=2)@1000: 0.42688547107019914, nDCG@10: 0.6929843235417926} \n",
      "\n",
      "... with fast-forward re-ranking AND early stopping (alpha=0.2):\n",
      " {RR(rel=2)@10: 0.8748615725359912, AP(rel=2)@1000: 0.4250957223020153, nDCG@10: 0.6929843235417926}\n"
     ]
    }
   ],
   "source": [
    "from ir_measures import calc_aggregate, AP, RR, nDCG\n",
    "from fast_forward.util import to_ir_measures\n",
    "\n",
    "alpha: float = 0.2\n",
    "eval_metrics = [AP(rel=2)@1000, RR(rel=2)@10, nDCG@10]\n",
    "print(\n",
    "    \"Sparse ranking:\\n\",\n",
    "    calc_aggregate(\n",
    "        eval_metrics, \n",
    "        dataset.qrels_iter(), \n",
    "        to_ir_measures(sparse_ranking)\n",
    "    ),\n",
    "    \"\\n\\nDense ranking:\\n\",\n",
    "    calc_aggregate(\n",
    "        eval_metrics, \n",
    "        dataset.qrels_iter(), \n",
    "        to_ir_measures(dense_ranking)\n",
    "    ),\n",
    "    f\"\\n\\n... with fast-forward re-ranking (alpha={alpha}):\\n\",\n",
    "    calc_aggregate(\n",
    "        eval_metrics,\n",
    "        dataset.qrels_iter(),\n",
    "        to_ir_measures(sparse_ranking.interpolate(dense_ranking, alpha)),\n",
    "    ),\n",
    "    f\"\\n\\n... with fast-forward re-ranking AND early stopping (alpha={alpha}):\\n\",\n",
    "    calc_aggregate(\n",
    "        eval_metrics,\n",
    "        dataset.qrels_iter(),\n",
    "        to_ir_measures(sparse_ranking.interpolate(dense_ranking_es, alpha)),\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
